{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "477cb21a-9a47-4f4e-af19-5e2ecc051789",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 16:06:41.029593: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "deepctr_path = '/root/linghui/rec-fairness/'\n",
    "sys.path.append(deepctr_path)\n",
    "import deepctr\n",
    "from deepctr.models import DeepFM\n",
    "from deepctr.feature_column import SparseFeat, VarLenSparseFeat, get_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cf845c1-6922-467a-9c13-6b9c7c6363d6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_feat_dict(data):\n",
    "    if data == 'ml-1m':\n",
    "        feat_dict = {'item_id': 3706,\n",
    "                 'user_id': 6040,\n",
    "                 'gender': 2,\n",
    "                 'age': 7,\n",
    "                 'occupation': 21,\n",
    "                 'zipcode': 3439}\n",
    "    if data == 'black-fri':\n",
    "        feat_dict = {'user_id': 5891,\n",
    "                 'item_id': 3631,\n",
    "                 'gender': 2,\n",
    "                 'age': 7,\n",
    "                 'occupation': 21,\n",
    "                 'city': 3,\n",
    "                 'stay_years': 5,\n",
    "                 'martial_status': 2,\n",
    "                 'cate': 20,\n",
    "                 'subcate_1': 18,\n",
    "                 'subcate_2': 16,\n",
    "                 'price': 23962}\n",
    "    return feat_dict\n",
    "\n",
    "def get_saved_model_details(model_params, data_params):\n",
    "    model_name = model_params['model_name']\n",
    "    cate = model_params['cate']\n",
    "    dataset = data_params['dataset']\n",
    "    if dataset == 'ml-1m':\n",
    "        if model_name == 'DeepFM':\n",
    "            # if cate == 'all-feat':\n",
    "            #     check_path = '/data/linghui/saved_model/deepfm-ml-1m/deepfm-all-feature/deepfm-ml-1m.ckpt'\n",
    "            #     train_feats = [\"item_id\", \"user_id\", \"gender\", \"age\", \"occupation\", \"zipcode\"]\n",
    "            # if cate == 'del-sf':\n",
    "            #     check_path = '/data/linghui/saved_model/deepfm-ml-1m/deepfm-del-sf/deepfm-ml-1m-del-sf.ckpt'\n",
    "            #     train_feats = [\"item_id\", \"user_id\"]\n",
    "            if cate == 'liuyi-all-feats':\n",
    "                check_path = '/data/linghui/saved_model/deepfm-ml-1m/deepfm-liuyi/deepfm-ml-1m-liuyi.ckpt'\n",
    "                train_feats = [\"item_id\", \"user_id\", \"gender\", \"age\", \"occupation\", \"zipcode\"]\n",
    "    if dataset == 'black-fri':\n",
    "        if model_name == 'DeepFM':\n",
    "            if cate == 'liuyi-all-feats':\n",
    "                check_path = '/data/linghui/saved_model/deepfm-black-fri/deepfm-black-fri-liuyi.ckpt'\n",
    "                train_feats = ['user_id','item_id','gender','age','occupation','city','stay_years','martial_status','cate','subcate_1','subcate_2','price']\n",
    "    return check_path , train_feats\n",
    "\n",
    "def get_model(model_params,data_params):\n",
    "    dataset = data_params['dataset']\n",
    "\n",
    "    model_name = model_params['model_name']\n",
    "    cate = model_params['cate']\n",
    "    embedding_dim = model_params['embedding_dim']\n",
    "    check_path, train_feats = get_saved_model_details(model_params,data_params)\n",
    "    \n",
    "    feat_dict = get_feat_dict(dataset)\n",
    "    fixlen_feature_columns = [SparseFeat(feat, feat_dict[feat], embedding_dim=embedding_dim)\n",
    "                                      for feat in train_feats]\n",
    "    linear_feature_columns = fixlen_feature_columns \n",
    "    dnn_feature_columns = fixlen_feature_columns \n",
    "    feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
    "    \n",
    "\n",
    "    if model_name == 'DeepFM':\n",
    "        model = DeepFM(linear_feature_columns, dnn_feature_columns, task='binary')\n",
    "    model.summary()\n",
    "    model.load_weights(check_path)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(), loss='binary_crossentropy',\n",
    "                  metrics=['AUC', 'Precision', 'Recall'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_single_rule(key,value):\n",
    "    return{key:value}\n",
    "\n",
    "def get_single_sparse_rule(df,features):\n",
    "    single_rule = []\n",
    "    feat_value = df[features].value_counts()\n",
    "    feat_value = feat_value.index\n",
    "    sparse_feat_value = feat_value.values.astype('int32')\n",
    "    for value in sparse_feat_value:\n",
    "        rule = create_single_rule(features,value)\n",
    "        single_rule.append(rule)\n",
    "    return single_rule\n",
    "\n",
    "def get_single_dense_rule(df,feature,k):\n",
    "    min_value = df[feature].min()\n",
    "    max_value = df[feature].max()\n",
    "    single_rule = []\n",
    "    d = math.ceil((max_value - min_value) / k)\n",
    "    for i in range(k):\n",
    "        x = min_value + i * d\n",
    "        y = x + d\n",
    "        single_rule.append({feature:[x,y]})\n",
    "    return single_rule\n",
    "\n",
    "def merge_two_dicts(x, y):\n",
    "    z = x.copy()\n",
    "    z.update(y)\n",
    "    return z\n",
    "\n",
    "def combine_rule(rule_dict_1,rule_dict_2):\n",
    "    len1 = len(rule_dict_1)\n",
    "    len2 = len(rule_dict_2)\n",
    "    all_rule = []\n",
    "    for i in range(len1):\n",
    "        rule1 = rule_dict_1[i]\n",
    "        for j in range(len2):\n",
    "            rule2 = rule_dict_2[j]\n",
    "            merge_rule = merge_two_dicts(rule1,rule2)\n",
    "            all_rule.append(merge_rule)\n",
    "    return all_rule\n",
    "\n",
    "def creat_sparse_rule_query(rule):\n",
    "    result = ''\n",
    "    key = rule.keys()\n",
    "    length = len(key)\n",
    "    count = 0\n",
    "    for i in key:\n",
    "        count = count + 1\n",
    "        result = result + '( ' + i +' == ' + str(rule[i]) + ')'\n",
    "        # elif i[0] == 'I':\n",
    "        #     result = result + '(' + str(rule[i][0]) + ' <= ' + i + ' <= ' +  str(rule[i][1]) + ')'\n",
    "        if count < length:\n",
    "            result = result + ' & '\n",
    "    return result\n",
    "\n",
    "def get_all_rule_dict(data,sparse_feats,dense_feats,dense_num):\n",
    "    single_rule_dict = []\n",
    "    all_rule_dict = []\n",
    "    if len(sparse_feats) > 0:\n",
    "        for feature in sparse_feats:\n",
    "            temp_rule = []\n",
    "            single_rule = get_single_sparse_rule(data,feature)  \n",
    "            single_rule_dict = single_rule_dict + single_rule\n",
    "            if len(all_rule_dict) > 0: \n",
    "                temp_rule = combine_rule(all_rule_dict,single_rule)\n",
    "            all_rule_dict = all_rule_dict + single_rule + temp_rule\n",
    "    if len(dense_feats) > 0:\n",
    "        for feature in dense_feats:\n",
    "            temp_rule = []\n",
    "            single_rule = get_single_dense_rule(data,feature,dense_num)  \n",
    "            single_rule_dict = single_rule_dict + single_rule\n",
    "            if len(all_rule_dict) > 0: \n",
    "                temp_rule = combine_rule(all_rule_dict,single_rule)\n",
    "            all_rule_dict = all_rule_dict + single_rule + temp_rule \n",
    "    return all_rule_dict\n",
    "\n",
    "def get_evaluate_data(data,rule):\n",
    "    result = creat_sparse_rule_query(rule)\n",
    "    select_group = data.query(result)\n",
    "    unselect_group = data.drop(select_group.index)\n",
    "\n",
    "    return select_group,unselect_group\n",
    "\n",
    "def cut_rule(length_all,length_group,theta):\n",
    "    x = length_group / length_all\n",
    "    if (x >= theta) & (x < 1-theta):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_test_data(x_file,y_file):\n",
    "    test_x = np.loadtxt(x_file)\n",
    "    test_y = np.loadtxt(y_file)\n",
    "\n",
    "    sparse_features = ['C' + str(i) for i in range(1, 27)]\n",
    "    dense_features = ['I' + str(i) for i in range(1, 14)]\n",
    "    features = sparse_features + dense_features\n",
    "\n",
    "    test_x = pd.DataFrame(test_x,columns=features)\n",
    "    test_y = pd.DataFrame(test_y,columns=['label'])\n",
    "\n",
    "    test = pd.concat([test_x, test_y], axis=1)\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c06162be-fdf1-4f1c-a736-8cb0b5bf29c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_ml_test_data(model_params,data_params):\n",
    "    #load test data\n",
    "    saved_data_path = '/data/linghui/ml-1m/processed_data/'\n",
    "    test_data_path = saved_data_path + 'test_data_liuyi.csv'\n",
    "    test_data = pd.read_csv(test_data_path,index_col=0)\n",
    "    \n",
    "    #get model info\n",
    "    check_path ,train_features = get_saved_model_details(model_params, data_params)\n",
    "    model = get_model(model_params,data_params)\n",
    "    \n",
    "    #get predict values\n",
    "    test_input = {name: test_data[name].values for name in train_features}\n",
    "    label = test_data['label'].values\n",
    "    y_true = label\n",
    "    y_pred = model.predict(test_input)\n",
    "\n",
    "    test_data['predict'] = y_pred\n",
    "    cate_list = [eval(s) for s in test_data['cate']]\n",
    "    test_data['cate'] = cate_list\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ac46992-ba2e-45cb-95d8-f46336aea9c8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 16:08:58.515757: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2022-07-14 16:08:58.529894: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-14 16:08:58.531236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:dc:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.62GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-07-14 16:08:58.531333: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-14 16:08:58.532614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: \n",
      "pciBusID: 0000:dd:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.62GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-07-14 16:08:58.532643: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-07-14 16:08:58.534377: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2022-07-14 16:08:58.536386: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2022-07-14 16:08:58.536695: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2022-07-14 16:08:58.538642: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-07-14 16:08:58.539473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-07-14 16:08:58.543727: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-07-14 16:08:58.543856: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-14 16:08:58.545252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-14 16:08:58.546583: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-14 16:08:58.547914: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-14 16:08:58.549160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1\n",
      "2022-07-14 16:08:58.549515: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-14 16:08:58.561734: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2500000000 Hz\n",
      "2022-07-14 16:08:58.566292: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e606c8f4c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-07-14 16:08:58.566317: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-07-14 16:08:58.898143: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-14 16:08:58.908483: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-14 16:08:58.909783: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e606cfc4f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-07-14 16:08:58.909810: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2022-07-14 16:08:58.909817: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2022-07-14 16:08:58.911286: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-14 16:08:58.912338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:dc:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.62GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-07-14 16:08:58.912438: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-14 16:08:58.913434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: \n",
      "pciBusID: 0000:dd:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.62GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-07-14 16:08:58.913478: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-07-14 16:08:58.913503: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2022-07-14 16:08:58.913518: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2022-07-14 16:08:58.913541: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2022-07-14 16:08:58.913556: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-07-14 16:08:58.913570: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-07-14 16:08:58.913586: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-07-14 16:08:58.913644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-14 16:08:58.914698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-14 16:08:58.916692: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-14 16:08:58.917789: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-14 16:08:58.918783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1\n",
      "2022-07-14 16:08:58.918840: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-07-14 16:08:59.942818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-07-14 16:08:59.942859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 1 \n",
      "2022-07-14 16:08:59.942869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N Y \n",
      "2022-07-14 16:08:59.942875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   Y N \n",
      "2022-07-14 16:08:59.943197: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-14 16:08:59.944302: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-14 16:08:59.945363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-14 16:08:59.946424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10273 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:dc:00.0, compute capability: 6.1)\n",
      "2022-07-14 16:08:59.947176: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-14 16:08:59.948303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10273 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:dd:00.0, compute capability: 6.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "item_id (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_id (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gender (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "age (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "occupation (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zipcode (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_item_id (Embedding)  (None, 1, 4)         14824       item_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_user_id (Embedding)  (None, 1, 4)         24160       user_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_gender (Embedding)   (None, 1, 4)         8           gender[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_age (Embedding)      (None, 1, 4)         28          age[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_occupation (Embeddin (None, 1, 4)         84          occupation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_zipcode (Embedding)  (None, 1, 4)         13756       zipcode[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "linear0sparse_emb_item_id (Embe (None, 1, 1)         3706        item_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "linear0sparse_emb_user_id (Embe (None, 1, 1)         6040        user_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "linear0sparse_emb_gender (Embed (None, 1, 1)         2           gender[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "linear0sparse_emb_age (Embeddin (None, 1, 1)         7           age[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "linear0sparse_emb_occupation (E (None, 1, 1)         21          occupation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "linear0sparse_emb_zipcode (Embe (None, 1, 1)         3439        zipcode[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "no_mask_3 (NoMask)              (None, 1, 4)         0           sparse_emb_item_id[0][0]         \n",
      "                                                                 sparse_emb_user_id[0][0]         \n",
      "                                                                 sparse_emb_gender[0][0]          \n",
      "                                                                 sparse_emb_age[0][0]             \n",
      "                                                                 sparse_emb_occupation[0][0]      \n",
      "                                                                 sparse_emb_zipcode[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "no_mask (NoMask)                (None, 1, 1)         0           linear0sparse_emb_item_id[0][0]  \n",
      "                                                                 linear0sparse_emb_user_id[0][0]  \n",
      "                                                                 linear0sparse_emb_gender[0][0]   \n",
      "                                                                 linear0sparse_emb_age[0][0]      \n",
      "                                                                 linear0sparse_emb_occupation[0][0\n",
      "                                                                 linear0sparse_emb_zipcode[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "no_mask_2 (NoMask)              (None, 1, 4)         0           sparse_emb_item_id[0][0]         \n",
      "                                                                 sparse_emb_user_id[0][0]         \n",
      "                                                                 sparse_emb_gender[0][0]          \n",
      "                                                                 sparse_emb_age[0][0]             \n",
      "                                                                 sparse_emb_occupation[0][0]      \n",
      "                                                                 sparse_emb_zipcode[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1, 24)        0           no_mask_3[0][0]                  \n",
      "                                                                 no_mask_3[1][0]                  \n",
      "                                                                 no_mask_3[2][0]                  \n",
      "                                                                 no_mask_3[3][0]                  \n",
      "                                                                 no_mask_3[4][0]                  \n",
      "                                                                 no_mask_3[5][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1, 6)         0           no_mask[0][0]                    \n",
      "                                                                 no_mask[1][0]                    \n",
      "                                                                 no_mask[2][0]                    \n",
      "                                                                 no_mask[3][0]                    \n",
      "                                                                 no_mask[4][0]                    \n",
      "                                                                 no_mask[5][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 4)         0           no_mask_2[0][0]                  \n",
      "                                                                 no_mask_2[1][0]                  \n",
      "                                                                 no_mask_2[2][0]                  \n",
      "                                                                 no_mask_2[3][0]                  \n",
      "                                                                 no_mask_2[4][0]                  \n",
      "                                                                 no_mask_2[5][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 24)           0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "linear (Linear)                 (None, 1, 1)         0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "fm (FM)                         (None, 1)            0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dnn (DNN)                       (None, 64)           47552       flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "no_mask_1 (NoMask)              (None, 1, 1)         0           linear[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 1)            0           fm[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            64          dnn[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 1, 1)         0           no_mask_1[0][0]                  \n",
      "                                                                 add[0][0]                        \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "prediction_layer (PredictionLay (None, 1)            1           add_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 113,692\n",
      "Trainable params: 113,692\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 16:09:01.553761: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n"
     ]
    }
   ],
   "source": [
    "# model_name: DeepFM / \n",
    "# cate : all-feat / del-sf\n",
    "\n",
    "model_params = {'model_name': 'DeepFM',\n",
    "                'cate': 'liuyi-all-feats',\n",
    "                'embedding_dim': 4,\n",
    "                'batch_size': 256 }\n",
    "\n",
    "data_params = {'dataset': 'ml-1m'}\n",
    "\n",
    "test_data = create_ml_test_data(model_params,data_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ac2e110-cbc3-4ca5-a887-01c0d05b9bf7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>label</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>cate</th>\n",
       "      <th>popularity</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>978824351</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1588</td>\n",
       "      <td>[1, 2, 15, 6]</td>\n",
       "      <td>0.038122</td>\n",
       "      <td>0.939831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1737</td>\n",
       "      <td>1</td>\n",
       "      <td>978300174</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>2248</td>\n",
       "      <td>[13]</td>\n",
       "      <td>0.111349</td>\n",
       "      <td>0.823337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1900</td>\n",
       "      <td>1</td>\n",
       "      <td>978298504</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1863</td>\n",
       "      <td>[11]</td>\n",
       "      <td>0.103604</td>\n",
       "      <td>0.927760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1774</td>\n",
       "      <td>1</td>\n",
       "      <td>978294282</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>140</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>0.113260</td>\n",
       "      <td>0.912610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>279</td>\n",
       "      <td>1</td>\n",
       "      <td>978246585</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>1938</td>\n",
       "      <td>[7]</td>\n",
       "      <td>0.070109</td>\n",
       "      <td>0.555670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301995</th>\n",
       "      <td>6039</td>\n",
       "      <td>2993</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>466</td>\n",
       "      <td>[8, 7, 14]</td>\n",
       "      <td>0.023235</td>\n",
       "      <td>0.171150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301996</th>\n",
       "      <td>6039</td>\n",
       "      <td>2166</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>466</td>\n",
       "      <td>[7, 14]</td>\n",
       "      <td>0.070511</td>\n",
       "      <td>0.419440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301997</th>\n",
       "      <td>6039</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>466</td>\n",
       "      <td>[3, 6]</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>0.032339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301998</th>\n",
       "      <td>6039</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>466</td>\n",
       "      <td>[8]</td>\n",
       "      <td>0.009153</td>\n",
       "      <td>0.333478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301999</th>\n",
       "      <td>6039</td>\n",
       "      <td>2870</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>466</td>\n",
       "      <td>[7, 10]</td>\n",
       "      <td>0.008148</td>\n",
       "      <td>0.049975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>302000 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  item_id  label  timestamp  gender  age  occupation  zipcode  \\\n",
       "0             0       47      1  978824351       0    0          10     1588   \n",
       "1             1     1737      1  978300174       1    6          16     2248   \n",
       "2             2     1900      1  978298504       1    2          15     1863   \n",
       "3             3     1774      1  978294282       1    4           7      140   \n",
       "4             4      279      1  978246585       1    2          20     1938   \n",
       "...         ...      ...    ...        ...     ...  ...         ...      ...   \n",
       "301995     6039     2993      0          0       1    2           6      466   \n",
       "301996     6039     2166      0          0       1    2           6      466   \n",
       "301997     6039      286      0          0       1    2           6      466   \n",
       "301998     6039       70      0          0       1    2           6      466   \n",
       "301999     6039     2870      0          0       1    2           6      466   \n",
       "\n",
       "                 cate  popularity   predict  \n",
       "0       [1, 2, 15, 6]    0.038122  0.939831  \n",
       "1                [13]    0.111349  0.823337  \n",
       "2                [11]    0.103604  0.927760  \n",
       "3              [2, 3]    0.113260  0.912610  \n",
       "4                 [7]    0.070109  0.555670  \n",
       "...               ...         ...       ...  \n",
       "301995     [8, 7, 14]    0.023235  0.171150  \n",
       "301996        [7, 14]    0.070511  0.419440  \n",
       "301997         [3, 6]    0.002917  0.032339  \n",
       "301998            [8]    0.009153  0.333478  \n",
       "301999        [7, 10]    0.008148  0.049975  \n",
       "\n",
       "[302000 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24eaac86-8144-407f-b6b2-fbdfcd11e3e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class rec_metrics(object):\n",
    "    def __init__(self, evaluate_data,k):\n",
    "        self.users = np.array(evaluate_data['user_id'].to_list())\n",
    "        self.y_true = np.array(evaluate_data['label'].to_list())\n",
    "        self.y_pred = np.array(evaluate_data['predict'].to_list())\n",
    "        self.item_id = np.array(evaluate_data['item_id'].to_list())\n",
    "        self.item_cate = np.array(evaluate_data['cate'].to_list())\n",
    "        self.item_pop = np.array(evaluate_data['popularity'].to_list())\n",
    "        self.k = k\n",
    "        self.select_cols = [self.y_true,self.y_pred,self.item_id,self.item_cate,self.item_pop]\n",
    "    def get_user_pred(self):\n",
    "        \"\"\"\n",
    "        divide the result into different group by user id\n",
    "\n",
    "        Args:\n",
    "        y_true: array, all true labels of the data\n",
    "        y_pred: array, the predicted score\n",
    "        users: array, user id\n",
    "\n",
    "        Return:\n",
    "        user_pred: dict, key is user id and value is the labels and scores of each user\n",
    "        \"\"\"\n",
    "        user_pred = {}\n",
    "        for i, u in enumerate(self.users):\n",
    "            if u not in user_pred:\n",
    "                # user_pred[u] = [[self.y_true[i]], [self.y_pred[i]],[self.item_id[i]],[self.item_cate[i]]]\n",
    "                user_pred[u] = [[feat[i]] for feat in self.select_cols]\n",
    "            else:\n",
    "                for index in range(len(self.select_cols)):\n",
    "                    user_pred[u][index].append(self.select_cols[index][i])\n",
    "                # user_pred[u][0].append(self.y_true[i])\n",
    "                # user_pred[u][1].append(self.y_pred[i])\n",
    "                # user_pred[u][2].append(self.item_id[i])\n",
    "                # user_pred[u][3].append(self.item_cate[i])\n",
    "        return user_pred\n",
    "    def get_user_topk(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        sort y_pred and find topk results\n",
    "        this function is used to find topk predicted scores\n",
    "        and the corresponding index is applied to find the corresponding labels\n",
    "\n",
    "        \"\"\"\n",
    "        user_pred = self.get_user_pred()\n",
    "        for u in user_pred:\n",
    "            idx = np.argsort(user_pred[u][1])[::-1][:self.k]\n",
    "            for i in range(len(self.select_cols)):\n",
    "                user_pred[u][i] = np.array(user_pred[u][i])[idx]\n",
    "        return user_pred\n",
    "\n",
    "    def auc_score(self):\n",
    "        return roc_auc_score(self.y_true, self.y_pred)\n",
    "    \n",
    "    def gauc_score(self,weights=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        y_true: array, dim(N, ), all true labels of the data\n",
    "        y_pred: array, dim(N, ), the predicted score\n",
    "        users: array, dim(N, ), user id\n",
    "        weight: dict, it contains weights for each group.\n",
    "            if it is None, the weight is equal to the number\n",
    "            of times the user is recommended\n",
    "        Return:\n",
    "        score: float, GAUC\n",
    "        \"\"\"\n",
    "        assert len(self.y_true) == len(self.y_pred) and len(self.y_true) == len(self.users)\n",
    "\n",
    "        user_pred = self.get_user_topk()\n",
    "        score = 0\n",
    "        num = 0\n",
    "        for u in user_pred.keys():\n",
    "            auc = auc_score(user_pred[u][0], user_pred[u][1])\n",
    "            if weights is None:\n",
    "                wg = len(user_pred[u][0])\n",
    "            else:\n",
    "                wg = weights[u]\n",
    "            auc *= wg\n",
    "            num += wg\n",
    "            score += auc\n",
    "        return score / num\n",
    "    \n",
    "    def log_loss(self):\n",
    "        score = self.y_true * np.log(self.y_pred) + (1 - self.y_true) * np.log(1 - self.y_pred)\n",
    "        return -score.sum() / len(self.y_true)\n",
    "    \n",
    "    def ndcg_score(self):\n",
    "        \"\"\"compute NDCG\n",
    "        Args:\n",
    "        user_pred: dict, computed by get_user_topk()\n",
    "        \"\"\"\n",
    "        user_pred = self.get_user_topk()\n",
    "        rank = np.arange(1, self.k+1, 1)\n",
    "        idcgs = 1. / np.log2(rank + 1)\n",
    "        idcg = sum(idcgs)\n",
    "        score = 0\n",
    "        for u in user_pred:\n",
    "            dcgs = idcgs[np.where(user_pred[u][0] == 1)]\n",
    "            dcg = sum(dcgs)\n",
    "            score += dcg / idcg\n",
    "        return score / len(user_pred.keys())\n",
    "    \n",
    "    def cate_diversity_score(self):\n",
    "        user_pred = self.get_user_topk()\n",
    "        score = 0\n",
    "        for u in user_pred:\n",
    "            item_list = user_pred[u][3]     \n",
    "            item_list = sum(item_list,[])  #bf delete  ml-1m:preserve\n",
    "            cate = set(item_list)\n",
    "            cate_num = len(cate)\n",
    "            score += cate_num\n",
    "        return score / len(user_pred.keys())\n",
    "    \n",
    "    def popularity_score(self):\n",
    "        user_pred = self.get_user_topk()\n",
    "        score = 0\n",
    "        for u in user_pred:\n",
    "            pop_list = user_pred[u][4]\n",
    "            pop_score = np.mean(pop_list)\n",
    "            score += pop_score\n",
    "        return score / len(user_pred.keys())\n",
    "    \n",
    "    def hit_score(self):\n",
    "        user_pred = self.get_user_topk()\n",
    "        score = 0\n",
    "        for u in user_pred:\n",
    "            if 1 in user_pred[u][0]:\n",
    "                score += 1.0\n",
    "        return score / len(user_pred.keys())\n",
    "    def mrr_score(self):\n",
    "        user_pred = self.get_user_topk()\n",
    "        score = 0\n",
    "        for u in user_pred:\n",
    "            if 1 in user_pred[u][0]:\n",
    "                score += 1.0 / (np.where(user_pred[u][0] == 1)[0][0] + 1)\n",
    "        return score / len(user_pred.keys())\n",
    "    def recall_score(self):\n",
    "        user_pred = self.get_user_topk()\n",
    "        score = 0\n",
    "        for u in user_pred:\n",
    "            score += sum(user_pred[u][0]) * 1. / len(user_pred[u][0])\n",
    "        return score / len(user_pred.keys())\n",
    "    \n",
    "    def get_all_metrics(self):\n",
    "        log_loss = self.log_loss()\n",
    "        auc_score = self.auc_score()\n",
    "        # gauc_score = self.gauc_score()\n",
    "        ndcg_score = self.ndcg_score(user_pred)\n",
    "        hit_score = self.hit_score(user_pred)\n",
    "        mrr_score = self.mrr_score(user_pred)\n",
    "        recall_score = self.recall_score(user_pred)\n",
    "        cate_diversity_score = self.cate_diversity_score(user_pred)\n",
    "        pop_score = self.popularity_score(user_pred)\n",
    "        \n",
    "        result = pd.DataFrame()\n",
    "        result['log_loss'] = [log_loss]\n",
    "        result['auc'] = [auc_score]\n",
    "        result['ndcg'] = [ndcg_score]\n",
    "        result['hit'] = [hit_score]\n",
    "        result['mrr'] = [mrr_score]\n",
    "        result['cate_diversity'] = [cate_diversity_score]\n",
    "        result['popularity'] = [pop_score]\n",
    "        return result\n",
    "    \n",
    "class rec_fairness_metrics(object):\n",
    "    def __init__(self, group_target, group_compare):\n",
    "        self.group_target = group_target\n",
    "        self.group_compare = group_compare\n",
    "        self.label_column = 'label'\n",
    "        self.pred_column = 'predict'\n",
    "        self.item_id = group_target['item_id'].unique()\n",
    "        \n",
    "        self.group_target_metrics = rec_metrics(group_target,5)\n",
    "        self.group_compare_metrics = rec_metrics(group_compare,5)\n",
    "    \n",
    "    def sub_pred_true(self,data):\n",
    "        y_true = np.array(data[self.label_column].to_list())\n",
    "        y_pred = np.array(data[self.pred_column].to_list())\n",
    "        result = np.mean(y_pred - y_true)\n",
    "        return result\n",
    "        \n",
    "    def value_unfairness(self,select_group,compare_group):\n",
    "        item_id = self.item_id\n",
    "        val_unfairness_list = []\n",
    "        for i in item_id:\n",
    "            user_select_group = select_group.loc[select_group['item_id'] == i]\n",
    "            if len(user_select_group) == 0:\n",
    "                val_target = 0\n",
    "            else:\n",
    "                val_target = self.sub_pred_true(user_select_group)\n",
    "            user_compare_group = compare_group.loc[compare_group['item_id'] == i]\n",
    "            if len(user_compare_group) == 0:\n",
    "                val_compare = 0\n",
    "            else:\n",
    "                val_compare = self.sub_pred_true(user_compare_group)\n",
    "            val_unfairness_list.append(val_target - val_compare)\n",
    "        return(np.mean(val_unfairness_list))\n",
    "    \n",
    "    def parity_unfairness(self,select_group,compare_group):\n",
    "        item_id = self.item_id\n",
    "        for i in item_id:\n",
    "            user_select_group = select_group.loc[select_group['item_id'] == i]\n",
    "            if len(user_select_group) == 0:\n",
    "                par_target = 0\n",
    "            else:\n",
    "                par_target = np.mean(user_select_group[self.pred_column].to_list())\n",
    "            user_compare_group = compare_group.loc[compare_group['item_id'] == i]\n",
    "            if len(user_compare_group) == 0:\n",
    "                par_compare = 0\n",
    "            else:\n",
    "                par_compare = np.mean(user_compare_group[self.pred_column].to_list())\n",
    "            parity_unfairness = par_target - par_compare\n",
    "        return parity_unfairness\n",
    "    \n",
    "    def metric_unfairness(self):\n",
    "        metrics_target = self.group_target_metrics.get_all_metrics()\n",
    "        metrics_compare = self.group_compare_metrics.get_all_metrics()\n",
    "        metrics_unfairness = metrics_target.to_numpy() - metrics_compare.to_numpy()\n",
    "        result_unfairness = pd.DataFrame(metrics_unfairness,columns=metrics_target.columns)\n",
    "        return result_unfairness\n",
    "    \n",
    "    def get_all_unfairness_metrics(self):\n",
    "        result_unfairness = self.metric_unfairness()\n",
    "        \n",
    "        select_group = self.group_target\n",
    "        compare_group = self.group_compare\n",
    "        value_unfairness = self.value_unfairness(select_group,compare_group)\n",
    "        parity_unfairness = self.parity_unfairness(select_group,compare_group)\n",
    "        \n",
    "        result_unfairness['value'] = value_unfairness\n",
    "        result_unfairness['parity'] = parity_unfairness\n",
    "        return result_unfairness\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b23ff257-ce56-4fb5-a793-0a34769e41d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sparse_rule_query(rule):\n",
    "    result = ''\n",
    "    key = rule.keys()\n",
    "    length = len(key)\n",
    "    count = 0\n",
    "    for i in key:\n",
    "        count = count + 1\n",
    "        result = result + '( ' + i +' == ' + str(rule[i]) + ')'\n",
    "        # elif i[0] == 'I':\n",
    "        #     result = result + '(' + str(rule[i][0]) + ' <= ' + i + ' <= ' +  str(rule[i][1]) + ')'\n",
    "        if count < length:\n",
    "            result = result + ' & '\n",
    "    return result\n",
    "\n",
    "def create_single_rule(feats,value):\n",
    "    rule = {}\n",
    "    for i in range(len(feats)):\n",
    "        rule[feats[i]] = value[i]\n",
    "    return rule\n",
    "\n",
    "# sensitive_feats = ['gender','age','occupation']\n",
    "# value = [0,0,0]\n",
    "# rule = create_single_rule(sensitive_feats,value)\n",
    "# re = create_sparse_rule_query(rule)\n",
    "# re\n",
    "# # q = '(' + 'gender' + '==' + str(0)\n",
    "# # test_data.query(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b0fc97f-7b00-4b4c-82dc-0b928abb913f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_rule_list = []\n",
    "value_list = []\n",
    "threshold = 0.01\n",
    "sensitive_feats = ['gender','age','occupation']\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(7):\n",
    "        for k in range(21):\n",
    "            rule = create_single_rule(sensitive_feats,[i,j,k])\n",
    "            rule_query = create_sparse_rule_query(rule)\n",
    "            select_group = test_data.query(rule_query)\n",
    "            if (select_group['user_id'].nunique() / test_data['user_id'].nunique()) >= threshold:\n",
    "                all_rule_list.append(rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "553b612a-c082-45ba-93f5-be85dfef6879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_rule_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8e357996-7660-4004-9383-1e0fbb54ba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "save_result = pd.DataFrame(columns = a.columns)\n",
    "for rule in all_rule_list:\n",
    "    rule_query = create_sparse_rule_query(rule)\n",
    "    group_target = test_data.query(rule_query)\n",
    "    group_compare = test_data.drop(group_target.index)\n",
    "    result = rec_fairness_metrics(group_target,group_compare)\n",
    "    metric_result = result.get_all_unfairness_metrics()\n",
    "    save_result = save_result.append(metric_result)\n",
    "end_time = time.time()\n",
    "time_all = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8768bcc0-1561-4129-b4ab-f27bcd4f8f6c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_loss</th>\n",
       "      <th>auc</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>hit</th>\n",
       "      <th>mrr</th>\n",
       "      <th>cate_diversity</th>\n",
       "      <th>popularity</th>\n",
       "      <th>value</th>\n",
       "      <th>parity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.024743</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>0.039995</td>\n",
       "      <td>-0.008083</td>\n",
       "      <td>0.719270</td>\n",
       "      <td>-0.008011</td>\n",
       "      <td>-0.026996</td>\n",
       "      <td>0.085882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.017021</td>\n",
       "      <td>0.005895</td>\n",
       "      <td>0.010060</td>\n",
       "      <td>-0.002860</td>\n",
       "      <td>0.040136</td>\n",
       "      <td>0.135625</td>\n",
       "      <td>0.001514</td>\n",
       "      <td>-0.005102</td>\n",
       "      <td>-0.006341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.039952</td>\n",
       "      <td>-0.038100</td>\n",
       "      <td>-0.018469</td>\n",
       "      <td>-0.080699</td>\n",
       "      <td>-0.045881</td>\n",
       "      <td>-0.464738</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.016348</td>\n",
       "      <td>0.105340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021551</td>\n",
       "      <td>-0.007334</td>\n",
       "      <td>0.012953</td>\n",
       "      <td>0.058884</td>\n",
       "      <td>0.030712</td>\n",
       "      <td>-0.221054</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>0.012878</td>\n",
       "      <td>-0.006901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025816</td>\n",
       "      <td>-0.000612</td>\n",
       "      <td>0.020057</td>\n",
       "      <td>0.001187</td>\n",
       "      <td>0.078207</td>\n",
       "      <td>-0.203790</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>0.011511</td>\n",
       "      <td>0.035636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.037177</td>\n",
       "      <td>0.024511</td>\n",
       "      <td>0.022840</td>\n",
       "      <td>0.081886</td>\n",
       "      <td>0.062225</td>\n",
       "      <td>-0.176229</td>\n",
       "      <td>-0.003489</td>\n",
       "      <td>-0.024748</td>\n",
       "      <td>-0.072339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.013890</td>\n",
       "      <td>-0.000772</td>\n",
       "      <td>0.010280</td>\n",
       "      <td>0.056355</td>\n",
       "      <td>0.022301</td>\n",
       "      <td>0.132091</td>\n",
       "      <td>-0.002724</td>\n",
       "      <td>-0.007952</td>\n",
       "      <td>-0.010402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.052901</td>\n",
       "      <td>0.009668</td>\n",
       "      <td>0.008906</td>\n",
       "      <td>0.037381</td>\n",
       "      <td>0.022441</td>\n",
       "      <td>0.024759</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>-0.026514</td>\n",
       "      <td>-0.113117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.020789</td>\n",
       "      <td>-0.019712</td>\n",
       "      <td>-0.003443</td>\n",
       "      <td>-0.011915</td>\n",
       "      <td>-0.009945</td>\n",
       "      <td>0.052358</td>\n",
       "      <td>-0.000966</td>\n",
       "      <td>0.014986</td>\n",
       "      <td>-0.334100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.020985</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>-0.026308</td>\n",
       "      <td>-0.074800</td>\n",
       "      <td>-0.078431</td>\n",
       "      <td>-0.219694</td>\n",
       "      <td>-0.003159</td>\n",
       "      <td>-0.005334</td>\n",
       "      <td>-0.068364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003608</td>\n",
       "      <td>-0.005127</td>\n",
       "      <td>-0.014052</td>\n",
       "      <td>-0.031112</td>\n",
       "      <td>-0.044429</td>\n",
       "      <td>-0.007066</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>0.011874</td>\n",
       "      <td>0.324257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.030142</td>\n",
       "      <td>-0.008104</td>\n",
       "      <td>-0.011841</td>\n",
       "      <td>-0.048692</td>\n",
       "      <td>-0.029790</td>\n",
       "      <td>-0.276794</td>\n",
       "      <td>-0.002535</td>\n",
       "      <td>-0.011991</td>\n",
       "      <td>-0.011527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.012705</td>\n",
       "      <td>0.012024</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>-0.003670</td>\n",
       "      <td>0.004410</td>\n",
       "      <td>0.098494</td>\n",
       "      <td>0.004359</td>\n",
       "      <td>-0.009996</td>\n",
       "      <td>-0.010685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.023871</td>\n",
       "      <td>0.023775</td>\n",
       "      <td>0.008962</td>\n",
       "      <td>0.049934</td>\n",
       "      <td>0.018882</td>\n",
       "      <td>-0.151322</td>\n",
       "      <td>0.006180</td>\n",
       "      <td>-0.016734</td>\n",
       "      <td>-0.043342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002684</td>\n",
       "      <td>0.028386</td>\n",
       "      <td>0.025152</td>\n",
       "      <td>0.123545</td>\n",
       "      <td>0.058099</td>\n",
       "      <td>0.017066</td>\n",
       "      <td>0.012034</td>\n",
       "      <td>-0.003264</td>\n",
       "      <td>0.081595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.018362</td>\n",
       "      <td>-0.002161</td>\n",
       "      <td>0.006313</td>\n",
       "      <td>0.009708</td>\n",
       "      <td>0.021846</td>\n",
       "      <td>0.048123</td>\n",
       "      <td>0.002464</td>\n",
       "      <td>-0.014492</td>\n",
       "      <td>-0.542986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.040926</td>\n",
       "      <td>-0.039326</td>\n",
       "      <td>-0.021422</td>\n",
       "      <td>-0.074957</td>\n",
       "      <td>-0.059276</td>\n",
       "      <td>0.283450</td>\n",
       "      <td>0.002718</td>\n",
       "      <td>0.019598</td>\n",
       "      <td>0.008546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.012156</td>\n",
       "      <td>-0.008942</td>\n",
       "      <td>-0.030531</td>\n",
       "      <td>-0.069662</td>\n",
       "      <td>-0.097390</td>\n",
       "      <td>-0.332286</td>\n",
       "      <td>-0.006159</td>\n",
       "      <td>-0.000381</td>\n",
       "      <td>-0.276540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009390</td>\n",
       "      <td>0.022864</td>\n",
       "      <td>0.033976</td>\n",
       "      <td>0.070783</td>\n",
       "      <td>0.110778</td>\n",
       "      <td>-0.135559</td>\n",
       "      <td>0.005864</td>\n",
       "      <td>0.001303</td>\n",
       "      <td>-0.253377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.015075</td>\n",
       "      <td>0.009563</td>\n",
       "      <td>0.013533</td>\n",
       "      <td>0.084009</td>\n",
       "      <td>0.024973</td>\n",
       "      <td>-0.131748</td>\n",
       "      <td>-0.001393</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>-0.103624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.015694</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.005096</td>\n",
       "      <td>-0.030533</td>\n",
       "      <td>0.030485</td>\n",
       "      <td>0.094276</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>-0.008802</td>\n",
       "      <td>-0.210537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.016947</td>\n",
       "      <td>0.005847</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.006869</td>\n",
       "      <td>-0.000540</td>\n",
       "      <td>0.168898</td>\n",
       "      <td>0.003977</td>\n",
       "      <td>-0.007815</td>\n",
       "      <td>-0.400893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.001861</td>\n",
       "      <td>-0.022041</td>\n",
       "      <td>-0.064529</td>\n",
       "      <td>-0.065910</td>\n",
       "      <td>-0.060199</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>-0.001009</td>\n",
       "      <td>0.025230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018994</td>\n",
       "      <td>0.017300</td>\n",
       "      <td>0.009482</td>\n",
       "      <td>0.007287</td>\n",
       "      <td>0.035019</td>\n",
       "      <td>0.040525</td>\n",
       "      <td>-0.003514</td>\n",
       "      <td>0.016471</td>\n",
       "      <td>-0.077726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   log_loss       auc      ndcg       hit       mrr  cate_diversity  \\\n",
       "0 -0.024743  0.000878  0.001489  0.039995 -0.008083        0.719270   \n",
       "0 -0.017021  0.005895  0.010060 -0.002860  0.040136        0.135625   \n",
       "0  0.039952 -0.038100 -0.018469 -0.080699 -0.045881       -0.464738   \n",
       "0  0.021551 -0.007334  0.012953  0.058884  0.030712       -0.221054   \n",
       "0  0.025816 -0.000612  0.020057  0.001187  0.078207       -0.203790   \n",
       "0 -0.037177  0.024511  0.022840  0.081886  0.062225       -0.176229   \n",
       "0 -0.013890 -0.000772  0.010280  0.056355  0.022301        0.132091   \n",
       "0 -0.052901  0.009668  0.008906  0.037381  0.022441        0.024759   \n",
       "0  0.020789 -0.019712 -0.003443 -0.011915 -0.009945        0.052358   \n",
       "0 -0.020985  0.001425 -0.026308 -0.074800 -0.078431       -0.219694   \n",
       "0  0.003608 -0.005127 -0.014052 -0.031112 -0.044429       -0.007066   \n",
       "0 -0.030142 -0.008104 -0.011841 -0.048692 -0.029790       -0.276794   \n",
       "0 -0.012705  0.012024  0.000877 -0.003670  0.004410        0.098494   \n",
       "0 -0.023871  0.023775  0.008962  0.049934  0.018882       -0.151322   \n",
       "0  0.002684  0.028386  0.025152  0.123545  0.058099        0.017066   \n",
       "0 -0.018362 -0.002161  0.006313  0.009708  0.021846        0.048123   \n",
       "0  0.040926 -0.039326 -0.021422 -0.074957 -0.059276        0.283450   \n",
       "0 -0.012156 -0.008942 -0.030531 -0.069662 -0.097390       -0.332286   \n",
       "0  0.009390  0.022864  0.033976  0.070783  0.110778       -0.135559   \n",
       "0 -0.015075  0.009563  0.013533  0.084009  0.024973       -0.131748   \n",
       "0 -0.015694  0.000051  0.005096 -0.030533  0.030485        0.094276   \n",
       "0 -0.016947  0.005847  0.000658  0.006869 -0.000540        0.168898   \n",
       "0  0.000502  0.001861 -0.022041 -0.064529 -0.065910       -0.060199   \n",
       "0  0.018994  0.017300  0.009482  0.007287  0.035019        0.040525   \n",
       "\n",
       "   popularity     value    parity  \n",
       "0   -0.008011 -0.026996  0.085882  \n",
       "0    0.001514 -0.005102 -0.006341  \n",
       "0    0.000739  0.016348  0.105340  \n",
       "0    0.001430  0.012878 -0.006901  \n",
       "0   -0.000180  0.011511  0.035636  \n",
       "0   -0.003489 -0.024748 -0.072339  \n",
       "0   -0.002724 -0.007952 -0.010402  \n",
       "0    0.000419 -0.026514 -0.113117  \n",
       "0   -0.000966  0.014986 -0.334100  \n",
       "0   -0.003159 -0.005334 -0.068364  \n",
       "0    0.000653  0.011874  0.324257  \n",
       "0   -0.002535 -0.011991 -0.011527  \n",
       "0    0.004359 -0.009996 -0.010685  \n",
       "0    0.006180 -0.016734 -0.043342  \n",
       "0    0.012034 -0.003264  0.081595  \n",
       "0    0.002464 -0.014492 -0.542986  \n",
       "0    0.002718  0.019598  0.008546  \n",
       "0   -0.006159 -0.000381 -0.276540  \n",
       "0    0.005864  0.001303 -0.253377  \n",
       "0   -0.001393  0.000148 -0.103624  \n",
       "0    0.002786 -0.008802 -0.210537  \n",
       "0    0.003977 -0.007815 -0.400893  \n",
       "0    0.001011 -0.001009  0.025230  \n",
       "0   -0.003514  0.016471 -0.077726  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a42172ad-2885-49cb-b661-1e5f124b0afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203.2887134552002"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b47a08e9-9ed6-47a7-875e-393f6e27f003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros([5,3])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88c86682-0d4c-427a-80ba-ee7bfd140d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.font_manager:findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans.\n",
      "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n",
      "å½“å‰æœ€ä½³ä½ç½®ï¼š[ 1.  2. 18.]\n",
      "å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š21.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 36845 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 20195 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 36807 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 31243 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "WARNING:matplotlib.font_manager:findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans.\n",
      "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
      "/opt/conda/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 27425 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 25968 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 36866 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 24212 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 24230 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 36845 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 20195 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 27425 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 25968 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 36866 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 24212 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 24230 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 36807 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 31243 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as mpl\n",
    "mpl.rcParams['font.sans-serif'] = ['SimHei']\n",
    "\n",
    "\n",
    "class PSO:\n",
    "    def __init__(self, dimension, time, size, low, up, v_low, v_high):\n",
    "        # åˆå§‹åŒ–\n",
    "        self.dimension = dimension  # å˜é‡ä¸ªæ•°\n",
    "        self.time = time  # è¿­ä»£çš„ä»£æ•°\n",
    "        self.size = size  # ç§ç¾¤å¤§å°\n",
    "        self.bound = []  # å˜é‡çš„çº¦æŸèŒƒå›´\n",
    "        self.bound.append(low)\n",
    "        self.bound.append(up)\n",
    "        self.v_low = v_low\n",
    "        self.v_high = v_high\n",
    "        self.x = np.zeros((self.size, self.dimension))  # æ‰€æœ‰ç²’å­çš„ä½ç½®\n",
    "        self.v = np.zeros((self.size, self.dimension))  # æ‰€æœ‰ç²’å­çš„é€Ÿåº¦\n",
    "        self.p_best = np.zeros((self.size, self.dimension))  # æ¯ä¸ªç²’å­æœ€ä¼˜çš„ä½ç½®\n",
    "        self.g_best = np.zeros((1, self.dimension))[0]  # å…¨å±€æœ€ä¼˜çš„ä½ç½®\n",
    "\n",
    "        # åˆå§‹åŒ–ç¬¬0ä»£åˆå§‹å…¨å±€æœ€ä¼˜è§£\n",
    "        temp = -1000000\n",
    "        for i in range(self.size):\n",
    "            for j in range(self.dimension):\n",
    "                self.x[i][j] = random.uniform(self.bound[0][j], self.bound[1][j])\n",
    "                self.v[i][j] = random.uniform(self.v_low, self.v_high)\n",
    "            self.p_best[i] = self.x[i]  # å‚¨å­˜æœ€ä¼˜çš„ä¸ªä½“\n",
    "            fit = self.fitness(self.p_best[i])\n",
    "            # åšå‡ºä¿®æ”¹\n",
    "            if fit > temp:\n",
    "                self.g_best = self.p_best[i]\n",
    "                temp = fit\n",
    "\n",
    "    def fitness(self, x):\n",
    "        \"\"\"\n",
    "        ä¸ªä½“é€‚åº”å€¼è®¡ç®—\n",
    "        \"\"\"\n",
    "        x1 = x[0]\n",
    "        x2 = x[1]\n",
    "        x3 = x[2]\n",
    "        rule_query = create_sparse_rule_query(rule)\n",
    "        group_target = test_data.query(rule_query)\n",
    "        group_compare = test_data.drop(group_target.index)\n",
    "        result = rec_fairness_metrics(group_target,group_compare)\n",
    "        metric_result = result.get_all_unfairness_metrics()\n",
    "        # print(y)\n",
    "        return y\n",
    "\n",
    "    def update(self, size):\n",
    "        c1 = 2.0  # å­¦ä¹ å› å­\n",
    "        c2 = 2.0\n",
    "        w = 0.8  # è‡ªèº«æƒé‡å› å­\n",
    "        for i in range(size):\n",
    "            # æ›´æ–°é€Ÿåº¦\n",
    "            self.v[i] = w * self.v[i] + c1 * random.uniform(0, 1) * (\n",
    "                    self.p_best[i] - self.x[i]) + c2 * random.uniform(0, 1) * (self.g_best - self.x[i])\n",
    "            # é€Ÿåº¦é™åˆ¶\n",
    "            for j in range(self.dimension):\n",
    "                if self.v[i][j] < self.v_low:\n",
    "                    self.v[i][j] = self.v_low\n",
    "                if self.v[i][j] > self.v_high:\n",
    "                    self.v[i][j] = self.v_high\n",
    "\n",
    "            # æ›´æ–°ä½ç½®\n",
    "            self.x[i] = list(map(int,self.x[i] + self.v[i]))\n",
    "            # ä½ç½®é™åˆ¶\n",
    "            for j in range(self.dimension):\n",
    "                if self.x[i][j] < self.bound[0][j]:\n",
    "                    self.x[i][j] = self.bound[0][j]\n",
    "                if self.x[i][j] > self.bound[1][j]:\n",
    "                    self.x[i][j] = self.bound[1][j]\n",
    "            # æ›´æ–°p_bestå’Œg_best\n",
    "            if self.fitness(self.x[i]) > self.fitness(self.p_best[i]):\n",
    "                self.p_best[i] = self.x[i]\n",
    "            if self.fitness(self.x[i]) > self.fitness(self.g_best):\n",
    "                self.g_best = self.x[i]\n",
    "\n",
    "    def pso(self):\n",
    "        best = []\n",
    "        self.final_best = np.array([1, 2, 3])\n",
    "        for gen in range(self.time):\n",
    "            self.update(self.size)\n",
    "            if self.fitness(self.g_best) > self.fitness(self.final_best):\n",
    "                self.final_best = self.g_best.copy()\n",
    "            print('å½“å‰æœ€ä½³ä½ç½®ï¼š{}'.format(self.final_best))\n",
    "            temp = self.fitness(self.final_best)\n",
    "            print('å½“å‰çš„æœ€ä½³é€‚åº”åº¦ï¼š{}'.format(temp))\n",
    "            best.append(temp)\n",
    "        t = [i for i in range(self.time)]\n",
    "        plt.figure()\n",
    "        plt.plot(t, best, color='red', marker='.', ms=15)\n",
    "        plt.rcParams['axes.unicode_minus'] = False\n",
    "        plt.margins(0)\n",
    "        plt.xlabel(u\"è¿­ä»£æ¬¡æ•°\")  # Xè½´æ ‡ç­¾\n",
    "        plt.ylabel(u\"é€‚åº”åº¦\")  # Yè½´æ ‡ç­¾\n",
    "        plt.title(u\"è¿­ä»£è¿‡ç¨‹\")  # æ ‡é¢˜\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    time = 50\n",
    "    size = 50\n",
    "    dimension = 3\n",
    "    v_low = -1\n",
    "    v_high = 1\n",
    "    low = [0, 0, 0]\n",
    "    up = [1, 6, 20]\n",
    "    pso = PSO(dimension, time, size, low, up, v_low, v_high)\n",
    "    pso.pso()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836a4da5-d8f9-40f9-ac86-e0c8a22f15ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
